resources:
  accelerators: A100:1
  cloud: gcp
  region: us-central1

num_nodes: 1

workdir: .

file_mounts:
  /artifacts:
    name: skypilot-chatbot
    store: gcs
    mode: MOUNT

  ~/chatlogs:
    name: skypilot-chatbot-logs
    store: gcs
    mode: MOUNT

setup: |
  conda activate chatbot
  if [ $? -eq 0 ]; then
    echo 'conda env exists'
  else
    # Setup the environment
    conda create -n chatbot python=3.10 -y
    conda activate chatbot

    pip3 install -e .

    # Install pytorch
    pip install torch==1.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116

    # Install huggingface with the LLaMA commit
    pip install git+https://github.com/huggingface/transformers

    # Install alpaca
    git clone https://github.com/tatsu-lab/stanford_alpaca.git
    cd stanford_alpaca
    pip install -r requirements.txt
    cd -
  fi

  ln -s /artifacts/chatbot/13b/ckpt/ ~/alpaca-13b

run: |
  conda activate chatbot
  WORKER_IP=$(hostname -I | cut -d' ' -f1)
  CONTROLLER_PORT=21001
  WORKER_PORT=21002
  python3 -m fastchat.serve.model_worker \
    --model ~/alpaca-13b \
    --controller-address http://${CONTROLLER_IP}:${CONTROLLER_PORT} \
    --worker-address http://${WORKER_IP}:${WORKER_PORT} \
    --host 0.0.0.0 \
    --port ${WORKER_PORT}
